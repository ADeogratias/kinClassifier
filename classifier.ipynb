{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igOeYQNHQy01",
        "outputId": "66a9b187-7fca-4265-cd8a-6a2f04bdfaef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/capstone/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTxo9U4MRI4V",
        "outputId": "a6be4ab7-70f2-4a19-8f8e-87dbcd8da64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/capstone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuWXTKm9S6a8",
        "outputId": "60127445-b464-41dd-d0c0-76d1804c72e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3EcU2KhyQ01H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pd.read_csv('questions.csv')\n",
        "qa.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "brh4SsjCS8Rv",
        "outputId": "7b1ead48-3e9c-47db-8c76-740977ec0a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cb68764c894d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'questions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mqa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'questions.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile intents.json\n",
        "{\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"gusuhuza\",\n",
        "      \"patterns\": [\n",
        "        \"Muraho neza?\",\n",
        "        \"Muraho?\",\n",
        "        \"Yemwe muraho?\",\n",
        "        \"Nkeneye ubufasha\",\n",
        "        \"umva amakuru\",\n",
        "        \"umva amakuru yawe?\",\n",
        "        \"amakuru yawe?\",\n",
        "        \"Bimeze bite?\",\n",
        "        \"Bimeze bite se?\",\n",
        "        \"amakuru se?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"ndaho, ni iki nabafashaho kijyane n'amakuru y'imyororokere?\",\n",
        "        \"ni iki nabashaho kijyane n'amakuru y'imyororokere?\"\n",
        "      ]\n",
        "    },\n",
        "\n",
        "    {\n",
        "      \"tag\": \"amazina\",\n",
        "      \"patterns\": [\"Ese bakwita nde?\", \"ese ubundi uri nde?\", \"niko witwa nde?\", \n",
        "      \"Uri inde?\", \"ukora iki?\"],\n",
        "      \"responses\": [\n",
        "        \"Nitwa Mbaza, ikoranabuhanga rikugezaho amakuru ajyanye n'imyororokere\"\n",
        "      ]\n",
        "    },\n",
        "\n",
        "    {\n",
        "      \"tag\": \"gusezera\",\n",
        "      \"patterns\": [\"Murabeho\", \"ni ah'ubutaha\"],\n",
        "      \"responses\": [\n",
        "        \"ni ah'ubutaha\", \"Murakoze ni ah'ubutaha\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"ibitutsi\",\n",
        "      \"patterns\": [\n",
        "        \"Wa ndaya we\",\n",
        "        \"wa mbwa we\",\n",
        "        \"Wa kinu we\",\n",
        "        \"ufite ubwenge buke\",\n",
        "        \"yewe bwengetwa\",\n",
        "        \"wa kinyendaro we\",\n",
        "        \"gaswere\",\n",
        "        \"wa mutindi we\",\n",
        "        \"wa mushenziwe\",\n",
        "        \"Maheru\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Mwihangane iyo mvugo ntiyemerewe hano\",\n",
        "        \"Ntabwo nasubizo kuriyo mvugo.\"\n",
        "      ]\n",
        "    },\n",
        "      {\n",
        "      \"tag\": \"kurongora\",\n",
        "      \"patterns\": [\n",
        "        \"ni gute abantu bavugako baryamana?\",\n",
        "        \"mbwira uko imibonano mpuzabitsina umenyako yabaye?\",\n",
        "        \"nsobanurira uko imibonano mpuzabitsina ikorwa ite?\",\n",
        "        \"mbwira kum'imibonano mpuzabitsina?\",\n",
        "        \"Imibonano mpuzabitsina ikorwa ite?\",\n",
        "        \"Imibonano mpuzabitsina niki?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Imibonano mpuzabitsina ni igikorwa abantu babiri bakuru cyerekeye n'igitsina cyangwa imyorokere. Ibi bikubiyemo ibikorwa bitandukanye nko guhuza ibitsina, gusomana, no kwikinisha.\",\n",
        "        \"ubushakashatsi buvugako, imibonano mpuzabitsina ni igikorwa abantu babiri bakuru cyerekeye n'igitsina cyangwa imyorokere. Ibi bikubiyemo ibikorwa bitandukanye nko guhuza ibitsina, gusomana, no kwikinisha.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"igihe\",\n",
        "      \"patterns\": [\n",
        "        \"Ese na ryamana n'umuntu tudahuje ibitsina ryari?\",\n",
        "        \"ni rwari nakora imibonano mpuzabitsina?\",\n",
        "        \"nigute namenyako niteguye gukora imibonano mpuzabitsina?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Guhitamo igihe witeguye gukora imibonano mpuzabitsina ni icyemezo cyawe wenyine ushobora gufata. Ni ngombwa kumenya neza ko wumva amarangamutima n'ubwenge, ndetse ko umubiri wawe witeguye. Ugomba kandi gutekereza ku ngaruka zishobora guterwa no gukora imibonano mpuzabitsina, kandi ukareba neza ko ufite uburyo bwo kuringaniza urubyaro no kwirinda indwara zandurira mu mibonano mpuzabitsina.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"ingaruka\",\n",
        "      \"patterns\": [\n",
        "        \"nizihe ngaruka zo gusambana?\",\n",
        "        \"nizihe ngaruka zo kubonana n'umuntu mudahuje ibitsina?\",\n",
        "        \"nizihe ngaruka zo gusambana n'umuhungu?\",\n",
        "        \"nizihe ngaruka zo gusambana n'umukobwa?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Hariho ingaruka zitari nke zishobora guterwa no gukora imibonano mpuzabitsina, harimo gutwita utabigambiriye, indwara zandurira mu mibonano mpuzabitsina, ishavu yatrwa n'amarangamutima cyangwa imitekerereze, ndetse n’ihohoterwa rishingiye ku gitsina. Ni ngombwa kumenya izi ngaruka no gufata ingamba zo kwikingira, nko gukoresha uburyo bwo kuringaniza imbyaro n'udukingirizo, kwemeranya n'umukunzi wawe, no kureba neza ko uzi ibyo uri gukora, witeguye kandi watanze urushusya rwo gukora imibonano mpuzabitsina\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"Kuringaniza_imbyaro\",\n",
        "      \"patterns\": [\n",
        "        \"Kuringaniza imbyaro niki?\",\n",
        "        \"Kuringaniza imbyaro bivuze iki?\",\n",
        "        \"Kuki ari ngombwa kuringaniza imbyaro?\",\n",
        "        \"Kuringanize urubyaro bizanyica?\",\n",
        "        \"nzongera kubyara ni ndinganiza urubyaro?\",\n",
        "        \"kuki batubwira kuringaniza imbyaro?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Kuringaniza imbyaro bivuga uburyo bubuza gutwita haba guhagarika intanga ngabo kugera ku igi cyangwa kubuza kurekura burundu. Hariho ubwoko bwinshi butandukanye bwo kuringaniza imbyaro, harimo agakingirizo, ibinini. Ni ikinini gifatwa rimwe ku munsi. Icyakora imbogamizi zagaragaye ni uko abagore bamwe babyibagirwa. Inshinge: Ni agashinge umugore aterwa rimwe mu kwezi cyangwa mu mezi atatu kakamurinda gusama muri icyo gihe cyose ariko ntigafasha umuntu kwirinda kwandura Virusi itera SIDA cyangwa indwara zandurirwa mu mibonano mpuzabitsina.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"kuringaniza_byiza\",\n",
        "      \"patterns\": [\n",
        "        \"nubuhe buryo bwiza bwo kuringaniza urubyaro?\",\n",
        "        \"wangira iyihe nama yo kuringaniza urubyaryo?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Kuringaniza imbyaro bivuga uburyo bubuza gutwita haba guhagarika intanga ngabo kugera ku igi cyangwa kubuza kurekura burundu. Hariho ubwoko bwinshi butandukanye bwo kuringaniza imbyaro, harimo agakingirizo, ibinini. Ni ikinini gifatwa rimwe ku munsi. Icyakora imbogamizi zagaragaye ni uko abagore bamwe babyibagirwa. Inshinge: Ni agashinge umugore aterwa rimwe mu kwezi cyangwa mu mezi atatu kakamurinda gusama muri icyo gihe cyose ariko ntigafasha umuntu kwirinda kwandura Virusi itera SIDA cyangwa indwara zandurirwa mu mibonano mpuzabitsina.\"\n",
        "      ]\n",
        "    },\n",
        "\n",
        "    {\n",
        "      \"tag\": \"kutaringaniza\",\n",
        "      \"patterns\": [\n",
        "        \"Ingaruko zo kutaringaniza urubyaro nizihe?\",\n",
        "        \"Byajyenda gute ntaringanije urubyaro?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Kudakoresha uburyo bwo kuringaniza imbyaro bishobora gutuma utwita utabigambiriye, hashobora no kuza izindi ngaruka utateguye byahungabanya amashuri, akazi, n'imibanire y'ubuzima busanzwe bwawe. Byongeye kandi, kudakoresha uburyo bwo kuringaniza imbyaro bishobora kongera amahirwe yo kwandura indwara zandurira mu mibonano mpuzabitsina, zishobora kugira ingaruka zikomeye ku buzima iyo zitavuwe. Ni ngombwa gufata ingamba zo kwikingira ukoresheje uburyo bwo kuringaniza imbyaro no gukora imibonano mpuzabitsina itekanye.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"gutwita_mumihango\",\n",
        "      \"patterns\": [\n",
        "        \"Ese birashoboka gutwita uri mumihango?\",\n",
        "        \"Umukobwa uri mumihango ashobora gutwita?\",\n",
        "        \"bibaho gutwita uri mumihango?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Birashoboka ariko amahirwe ko biba ni make. Intanga zishobora kubaho mumubiri mugihe cyiminsi itanu, niba ukoze imibonano mpuzabitsina uri mu mihango nyuma y'aho igi rigasohoka, birashoboka gusama. Ni ngombwa gukoresha uburyo bwo kuringaniza imbyaro niba udashaka gusama, utitaye niba uri cyangwa utari mu gihe cy'imihango.\"\n",
        "      ]\n",
        "    },\n",
        "        {\n",
        "      \"tag\": \"indwara\",\n",
        "      \"patterns\": [\n",
        "        \"Ese nakwandura nkoze imibonano mpuzabitsina?\",\n",
        "        \"Nigute namenyako mfite indwara nyuma yimibonano mpuzabitsina?\",\n",
        "        \"umenyako ufite indwara wanduriye mumibonano gute mpuzabitsina?\",\n",
        "        \"umenyako ufite indwara wanduriye mumibonano gute?\",\n",
        "        \"birashoboka kurwara nakoze imibonano mpuzabitsina?\",\n",
        "        \"birashoboka kurwara nasambanye?\",\n",
        "        \"birashoboka kurwara naryamanye n'umusore?\",\n",
        "        \"birashoboka kurwara naryamanye n'umukobwa?\",\n",
        "        \"birashoboka kurwara naryamanye n'inkumi?\",\n",
        "        \"birashoboka kurwara naryamanye n'incuti yanjye?\",\n",
        "        \"birashoboka kurwara naryamanye n'incuti?\",\n",
        "        \"birashoboka kurwara nararanye n'incuti?\",\n",
        "        \"birashoboka kurwara nasambanye n'incuti?\",\n",
        "        \"nakwirinda gute indwara z'imibonano mpuzabitsina?\",\n",
        "        \"umenyako ufite indwara wanduriye mumibonano gute?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Indwara nyinshi zandurira mu mibonano mpuzabitsina ntizigaragaza ibimenyetso, bityo rero ni ngombwa kwipimisha buri gihe niba ukora imibonano mpuzabitsina. Bimwe mu bimenyetso bikunze kugaragara ku ndwara zandurira mu mibonano mpuzabitsina harimo kunyara inkari zidasanzwe, uburyaryate no kuribwa mu gihe cyo kwihagarika, ibisebe bikikije imyanya ndangagitsina cyangwa umunwa, n'ibimenyetso bisa n'ibicurane nk'umuriro no kwishima. Niba ufite impungenge ko ushobora kuba ufite indwara zandurira mu mibonano mpuzabitsina, vugana n’inzego z'ubuzima kandi wipimishe vuba bishoboka.Uburyo bwiza cyane bwo kwirinda indwara zandurira mu mibonano mpuzabitsina ni ugukoresha agakingirizo mugihe cy'imibonano mpuzabitsina. Ni ngombwa kandi kwipimisha buri gihe niba ukunze gukora imibonano mpuzabitsina, no kuganira n'uwo muyikorana mubwirana niba hari uyirwaye cyangwa se yarigeze kuyirwara.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"ihohotera\",\n",
        "      \"patterns\": [\n",
        "        \"nakora iki ndiguhohoterwa?\",\n",
        "        \"nabijyenza gute ndi guhohoterwa?\",\n",
        "        \"ko ntari gufatwa neza kandi ntashaka kugira ibibazo ntabijyenza gute?\",\n",
        "        \"ko nta meze neza kandi ntashaka kugira ibibazo kuko nabivuze?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Ihohoterwa rishingiye ku gitsina ni imyitwarire iyo ari yo yose itifuzwa cyangwa itifuzwa mu mibonano mpuzabitsina, nk'ibitekerezo, ibimenyetso, cyangwa guhuza umubiri, bitera ibidukikije bitameze neza cyangwa byangwa. Niba uhuye n’ihohoterwa rishingiye ku gitsina, ni ngombwa kubivuga no kubimenyesha umuyobozi wizewe, nka mwarimu, umujyanama, cyangwa umuyobozi. Urashobora kandi gusaba inshuti n'umuryango, hanyuma ugatekereza gushaka inama zumwuga. Ni ngombwa kwibuka ko ihohoterwa rishingiye ku gitsina ritigera ari amakosa yawe, kandi ufite uburenganzira bwo kubirwanya no gushaka ubutabera.\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTxECpOkTJsa",
        "outputId": "852d276a-b146-44a9-bb37-ada59a717164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing intents.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1qKqp237QKV",
        "outputId": "1ee19222-77a1-45f0-d55b-472d65598710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random #for choosing random responses\n",
        "import json #for reading the file random responses\n",
        "import pickle #for the model\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer #reduce the word to a stem\n",
        "from tensorflow.keras.models import Sequential, load_model \n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "import tensorflow.compat.v2 as tf\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "# from tf.keras.optimizers.experimental.SGD import SGD"
      ],
      "metadata": {
        "id": "Di6XHTdI-3XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "4WM4TQ5M78jS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents = json.loads(open('intents.json').read())"
      ],
      "metadata": {
        "id": "JZK6RnxF8CJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignoreLetters = ['?','!','.',',']\n",
        "\n",
        "# we loop through the dictionary from the json file\n",
        "for intent in intents['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    word_list = nltk.word_tokenize(pattern) # split words\n",
        "    words.extend(word_list)\n",
        "    documents.append(((word_list), intent['tag'])) # track word tag\n",
        "    if intent['tag'] not in classes:\n",
        "      classes.append(intent['tag'])\n",
        "\n",
        "#we have everything in one list\n",
        "print(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6GEltz88E2b",
        "outputId": "1b80cfc9-e6fb-4ec2-9e6e-29269dbbe569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['Muraho', 'neza', '?'], 'gusuhuza'), (['Muraho', '?'], 'gusuhuza'), (['Yemwe', 'muraho', '?'], 'gusuhuza'), (['Nkeneye', 'ubufasha'], 'gusuhuza'), (['umva', 'amakuru'], 'gusuhuza'), (['umva', 'amakuru', 'yawe', '?'], 'gusuhuza'), (['amakuru', 'yawe', '?'], 'gusuhuza'), (['Bimeze', 'bite', '?'], 'gusuhuza'), (['Bimeze', 'bite', 'se', '?'], 'gusuhuza'), (['amakuru', 'se', '?'], 'gusuhuza'), (['Ese', 'bakwita', 'nde', '?'], 'amazina'), (['ese', 'ubundi', 'uri', 'nde', '?'], 'amazina'), (['niko', 'witwa', 'nde', '?'], 'amazina'), (['Uri', 'inde', '?'], 'amazina'), (['ukora', 'iki', '?'], 'amazina'), (['Murabeho'], 'gusezera'), (['ni', \"ah'ubutaha\"], 'gusezera'), (['Wa', 'ndaya', 'we'], 'ibitutsi'), (['wa', 'mbwa', 'we'], 'ibitutsi'), (['Wa', 'kinu', 'we'], 'ibitutsi'), (['ufite', 'ubwenge', 'buke'], 'ibitutsi'), (['yewe', 'bwengetwa'], 'ibitutsi'), (['wa', 'kinyendaro', 'we'], 'ibitutsi'), (['gaswere'], 'ibitutsi'), (['wa', 'mutindi', 'we'], 'ibitutsi'), (['wa', 'mushenziwe'], 'ibitutsi'), (['Maheru'], 'ibitutsi'), (['ni', 'gute', 'abantu', 'bavugako', 'baryamana', '?'], 'kurongora'), (['mbwira', 'uko', 'imibonano', 'mpuzabitsina', 'umenyako', 'yabaye', '?'], 'kurongora'), (['nsobanurira', 'uko', 'imibonano', 'mpuzabitsina', 'ikorwa', 'ite', '?'], 'kurongora'), (['mbwira', \"kum'imibonano\", 'mpuzabitsina', '?'], 'kurongora'), (['Imibonano', 'mpuzabitsina', 'ikorwa', 'ite', '?'], 'kurongora'), (['Imibonano', 'mpuzabitsina', 'niki', '?'], 'kurongora'), (['Ese', 'na', 'ryamana', \"n'umuntu\", 'tudahuje', 'ibitsina', 'ryari', '?'], 'igihe'), (['ni', 'rwari', 'nakora', 'imibonano', 'mpuzabitsina', '?'], 'igihe'), (['nigute', 'namenyako', 'niteguye', 'gukora', 'imibonano', 'mpuzabitsina', '?'], 'igihe'), (['nizihe', 'ngaruka', 'zo', 'gusambana', '?'], 'ingaruka'), (['nizihe', 'ngaruka', 'zo', 'kubonana', \"n'umuntu\", 'mudahuje', 'ibitsina', '?'], 'ingaruka'), (['nizihe', 'ngaruka', 'zo', 'gusambana', \"n'umuhungu\", '?'], 'ingaruka'), (['nizihe', 'ngaruka', 'zo', 'gusambana', \"n'umukobwa\", '?'], 'ingaruka'), (['Kuringaniza', 'imbyaro', 'niki', '?'], 'Kuringaniza_imbyaro'), (['Kuringaniza', 'imbyaro', 'bivuze', 'iki', '?'], 'Kuringaniza_imbyaro'), (['Kuki', 'ari', 'ngombwa', 'kuringaniza', 'imbyaro', '?'], 'Kuringaniza_imbyaro'), (['Kuringanize', 'urubyaro', 'bizanyica', '?'], 'Kuringaniza_imbyaro'), (['nzongera', 'kubyara', 'ni', 'ndinganiza', 'urubyaro', '?'], 'Kuringaniza_imbyaro'), (['kuki', 'batubwira', 'kuringaniza', 'imbyaro', '?'], 'Kuringaniza_imbyaro'), (['nubuhe', 'buryo', 'bwiza', 'bwo', 'kuringaniza', 'urubyaro', '?'], 'kuringaniza_byiza'), (['wangira', 'iyihe', 'nama', 'yo', 'kuringaniza', 'urubyaryo', '?'], 'kuringaniza_byiza'), (['Ingaruko', 'zo', 'kutaringaniza', 'urubyaro', 'nizihe', '?'], 'kutaringaniza'), (['Byajyenda', 'gute', 'ntaringanije', 'urubyaro', '?'], 'kutaringaniza'), (['Ese', 'birashoboka', 'gutwita', 'uri', 'mumihango', '?'], 'gutwita_mumihango'), (['Umukobwa', 'uri', 'mumihango', 'ashobora', 'gutwita', '?'], 'gutwita_mumihango'), (['bibaho', 'gutwita', 'uri', 'mumihango', '?'], 'gutwita_mumihango'), (['Ese', 'nakwandura', 'nkoze', 'imibonano', 'mpuzabitsina', '?'], 'indwara'), (['Nigute', 'namenyako', 'mfite', 'indwara', 'nyuma', 'yimibonano', 'mpuzabitsina', '?'], 'indwara'), (['umenyako', 'ufite', 'indwara', 'wanduriye', 'mumibonano', 'gute', 'mpuzabitsina', '?'], 'indwara'), (['umenyako', 'ufite', 'indwara', 'wanduriye', 'mumibonano', 'gute', '?'], 'indwara'), (['birashoboka', 'kurwara', 'nakoze', 'imibonano', 'mpuzabitsina', '?'], 'indwara'), (['birashoboka', 'kurwara', 'nasambanye', '?'], 'indwara'), (['birashoboka', 'kurwara', 'naryamanye', \"n'umusore\", '?'], 'indwara'), (['birashoboka', 'kurwara', 'naryamanye', \"n'umukobwa\", '?'], 'indwara'), (['birashoboka', 'kurwara', 'naryamanye', \"n'inkumi\", '?'], 'indwara'), (['birashoboka', 'kurwara', 'naryamanye', \"n'incuti\", 'yanjye', '?'], 'indwara'), (['birashoboka', 'kurwara', 'naryamanye', \"n'incuti\", '?'], 'indwara'), (['birashoboka', 'kurwara', 'nararanye', \"n'incuti\", '?'], 'indwara'), (['birashoboka', 'kurwara', 'nasambanye', \"n'incuti\", '?'], 'indwara'), (['nakwirinda', 'gute', 'indwara', \"z'imibonano\", 'mpuzabitsina', '?'], 'indwara'), (['umenyako', 'ufite', 'indwara', 'wanduriye', 'mumibonano', 'gute', '?'], 'indwara'), (['nakora', 'iki', 'ndiguhohoterwa', '?'], 'ihohotera'), (['nabijyenza', 'gute', 'ndi', 'guhohoterwa', '?'], 'ihohotera'), (['ko', 'ntari', 'gufatwa', 'neza', 'kandi', 'ntashaka', 'kugira', 'ibibazo', 'ntabijyenza', 'gute', '?'], 'ihohotera'), (['ko', 'nta', 'meze', 'neza', 'kandi', 'ntashaka', 'kugira', 'ibibazo', 'kuko', 'nabivuze', '?'], 'ihohotera')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmitizing all the words\n",
        "words = [lemmatizer.lemmatize(word) for word in words if word not in ignoreLetters]\n",
        "# remove duplicates and sorted to make it a list\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ],
      "metadata": {
        "id": "El0SBt2N-n6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the lemmatized lists\n",
        "pickle.dump(words, open('words.pkl', 'wb'))\n",
        "pickle.dump(classes, open('classes.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "gbKlGExC_PCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4dq7EVB_Wqa",
        "outputId": "74e7279c-1d14-4053-aeee-43a14c8cac1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes.pkl  drive  intents.json  sample_data  words.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#bag of words\n",
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "for document in documents:\n",
        "  bag = []\n",
        "  word_patterns = document[0]\n",
        "  word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
        "  for word in words:\n",
        "    bag.append(1) if word in word_patterns else bag.append(0)\n",
        "  \n",
        "  output_row = list(output_empty)\n",
        "  output_row[classes.index(document[1])] = 1\n",
        "  training.append([bag, output_row])"
      ],
      "metadata": {
        "id": "7hjzi0np_djp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffleling the data\n",
        "random.shuffle(training)\n",
        "training = np.array(training)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FVdVlXy_mGV",
        "outputId": "37cb413d-87ad-4559-a568-c2e36843ec69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ed3f9e9eb549>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  training = np.array(training)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data train and test list\n",
        "train_x = list(training[:, 0]) #features \n",
        "train_y = list(training[:, 1]) #labels"
      ],
      "metadata": {
        "id": "oDcq5LTr_o3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scheduler for learning rate\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=1e-6)\n",
        "\n",
        "# build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "sgd = tf.keras.optimizers.experimental.SGD(learning_rate= lr_schedule, momentum=0.9, nesterov=True)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = sgd,metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "sQEzpY22_249"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmhbeRAu_9UC",
        "outputId": "987d7b91-c0df-4a75-d102-5640f1692030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "15/15 [==============================] - 1s 3ms/step - loss: 2.5576 - accuracy: 0.0556 \n",
            "Epoch 2/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.4813 - accuracy: 0.1944\n",
            "Epoch 3/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.3033 - accuracy: 0.2361\n",
            "Epoch 4/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.1709 - accuracy: 0.3056\n",
            "Epoch 5/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.0740 - accuracy: 0.2778\n",
            "Epoch 6/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.8383 - accuracy: 0.3750\n",
            "Epoch 7/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.7036 - accuracy: 0.5278\n",
            "Epoch 8/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.6166 - accuracy: 0.5417\n",
            "Epoch 9/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.4560 - accuracy: 0.6250\n",
            "Epoch 10/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.3036 - accuracy: 0.6389\n",
            "Epoch 11/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.2428 - accuracy: 0.6528\n",
            "Epoch 12/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.1017 - accuracy: 0.7500\n",
            "Epoch 13/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.9521 - accuracy: 0.7639\n",
            "Epoch 14/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.9021 - accuracy: 0.7500\n",
            "Epoch 15/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.9674 - accuracy: 0.7222\n",
            "Epoch 16/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.8421 - accuracy: 0.8056\n",
            "Epoch 17/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7573 - accuracy: 0.7778\n",
            "Epoch 18/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6772 - accuracy: 0.8333\n",
            "Epoch 19/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.8056\n",
            "Epoch 20/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.9028\n",
            "Epoch 21/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.8472\n",
            "Epoch 22/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.8333\n",
            "Epoch 23/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8889\n",
            "Epoch 24/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.8750\n",
            "Epoch 25/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.8333\n",
            "Epoch 26/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.9306\n",
            "Epoch 27/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8611\n",
            "Epoch 28/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.9306\n",
            "Epoch 29/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.9306\n",
            "Epoch 30/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.9028\n",
            "Epoch 31/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8750\n",
            "Epoch 32/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.9583\n",
            "Epoch 33/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.8889\n",
            "Epoch 34/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.9583\n",
            "Epoch 35/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.9306\n",
            "Epoch 36/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.9583\n",
            "Epoch 37/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.9167\n",
            "Epoch 38/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.9306\n",
            "Epoch 39/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.9444\n",
            "Epoch 40/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.9028\n",
            "Epoch 41/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.9306\n",
            "Epoch 42/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.9028\n",
            "Epoch 43/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9583\n",
            "Epoch 44/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.9167\n",
            "Epoch 45/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8889\n",
            "Epoch 46/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2088 - accuracy: 0.9722\n",
            "Epoch 47/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9722\n",
            "Epoch 48/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9722\n",
            "Epoch 49/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8750\n",
            "Epoch 50/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.9722\n",
            "Epoch 51/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2570 - accuracy: 0.9583\n",
            "Epoch 52/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.9444\n",
            "Epoch 53/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9306\n",
            "Epoch 54/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.9028\n",
            "Epoch 55/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.9306\n",
            "Epoch 56/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9583\n",
            "Epoch 57/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9444\n",
            "Epoch 58/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9444\n",
            "Epoch 59/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9167\n",
            "Epoch 60/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2894 - accuracy: 0.9167\n",
            "Epoch 61/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9722\n",
            "Epoch 62/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9444\n",
            "Epoch 63/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.3082 - accuracy: 0.9167\n",
            "Epoch 64/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9583\n",
            "Epoch 65/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9306\n",
            "Epoch 66/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9861\n",
            "Epoch 67/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.9444\n",
            "Epoch 68/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9444\n",
            "Epoch 69/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9722\n",
            "Epoch 70/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.9444\n",
            "Epoch 71/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2198 - accuracy: 0.9444\n",
            "Epoch 72/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9583\n",
            "Epoch 73/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9306\n",
            "Epoch 74/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9444\n",
            "Epoch 75/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9722\n",
            "Epoch 76/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9583\n",
            "Epoch 77/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2410 - accuracy: 0.9306\n",
            "Epoch 78/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.9028\n",
            "Epoch 79/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9722\n",
            "Epoch 80/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9444\n",
            "Epoch 81/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9583\n",
            "Epoch 82/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1588 - accuracy: 0.9722\n",
            "Epoch 83/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9444\n",
            "Epoch 84/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9722\n",
            "Epoch 85/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9861\n",
            "Epoch 86/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1551 - accuracy: 0.9583\n",
            "Epoch 87/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9722\n",
            "Epoch 88/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9444\n",
            "Epoch 89/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9722\n",
            "Epoch 90/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9583\n",
            "Epoch 91/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9444\n",
            "Epoch 92/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9722\n",
            "Epoch 93/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9861\n",
            "Epoch 94/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9583\n",
            "Epoch 95/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9722\n",
            "Epoch 96/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9583\n",
            "Epoch 97/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.9722\n",
            "Epoch 98/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9306\n",
            "Epoch 99/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2008 - accuracy: 0.9583\n",
            "Epoch 100/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.9583\n",
            "Epoch 101/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9861\n",
            "Epoch 102/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.9444\n",
            "Epoch 103/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2040 - accuracy: 0.9444\n",
            "Epoch 104/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9306\n",
            "Epoch 105/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9444\n",
            "Epoch 106/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9722\n",
            "Epoch 107/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9306\n",
            "Epoch 108/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9722\n",
            "Epoch 109/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1950 - accuracy: 0.9583\n",
            "Epoch 110/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.9444\n",
            "Epoch 111/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9861\n",
            "Epoch 112/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9583\n",
            "Epoch 113/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1731 - accuracy: 0.9722\n",
            "Epoch 114/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9722\n",
            "Epoch 115/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1518 - accuracy: 0.9583\n",
            "Epoch 116/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9722\n",
            "Epoch 117/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9861\n",
            "Epoch 118/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9722\n",
            "Epoch 119/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9722\n",
            "Epoch 120/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9861\n",
            "Epoch 121/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9583\n",
            "Epoch 122/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9583\n",
            "Epoch 123/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9444\n",
            "Epoch 124/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9861\n",
            "Epoch 125/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2097 - accuracy: 0.9444\n",
            "Epoch 126/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9444\n",
            "Epoch 127/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9583\n",
            "Epoch 128/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9583\n",
            "Epoch 129/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9722\n",
            "Epoch 130/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9722\n",
            "Epoch 131/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9583\n",
            "Epoch 132/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1491 - accuracy: 0.9861\n",
            "Epoch 133/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9444\n",
            "Epoch 134/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9861\n",
            "Epoch 135/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.9444\n",
            "Epoch 136/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1343 - accuracy: 0.9583\n",
            "Epoch 137/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1717 - accuracy: 0.9583\n",
            "Epoch 138/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9444\n",
            "Epoch 139/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9861\n",
            "Epoch 140/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9722\n",
            "Epoch 141/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1516 - accuracy: 0.9583\n",
            "Epoch 142/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9167\n",
            "Epoch 144/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9861\n",
            "Epoch 145/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9583\n",
            "Epoch 146/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9583\n",
            "Epoch 147/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1002 - accuracy: 0.9861\n",
            "Epoch 148/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9722\n",
            "Epoch 149/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.9444\n",
            "Epoch 150/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9722\n",
            "Epoch 151/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9861\n",
            "Epoch 152/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9861\n",
            "Epoch 153/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9722\n",
            "Epoch 154/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9722\n",
            "Epoch 155/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9583\n",
            "Epoch 156/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9444\n",
            "Epoch 157/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9861\n",
            "Epoch 158/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.9444\n",
            "Epoch 159/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9861\n",
            "Epoch 160/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.9583\n",
            "Epoch 161/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1094 - accuracy: 0.9722\n",
            "Epoch 162/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9444\n",
            "Epoch 163/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9306\n",
            "Epoch 164/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9583\n",
            "Epoch 165/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9861\n",
            "Epoch 166/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9167\n",
            "Epoch 167/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9861\n",
            "Epoch 168/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9583\n",
            "Epoch 169/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9722\n",
            "Epoch 170/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.9722\n",
            "Epoch 171/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1251 - accuracy: 0.9722\n",
            "Epoch 172/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1685 - accuracy: 0.9306\n",
            "Epoch 173/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9722\n",
            "Epoch 174/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9722\n",
            "Epoch 175/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9444\n",
            "Epoch 176/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9861\n",
            "Epoch 177/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9583\n",
            "Epoch 178/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9861\n",
            "Epoch 179/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9444\n",
            "Epoch 180/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.9444\n",
            "Epoch 181/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1096 - accuracy: 0.9722\n",
            "Epoch 182/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9722\n",
            "Epoch 183/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9861\n",
            "Epoch 184/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9444\n",
            "Epoch 185/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9583\n",
            "Epoch 186/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9722\n",
            "Epoch 187/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9444\n",
            "Epoch 188/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9306\n",
            "Epoch 189/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9861\n",
            "Epoch 190/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.9722\n",
            "Epoch 191/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9722\n",
            "Epoch 192/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9861\n",
            "Epoch 193/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9722\n",
            "Epoch 194/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9583\n",
            "Epoch 195/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.9444\n",
            "Epoch 196/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9722\n",
            "Epoch 197/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9861\n",
            "Epoch 198/200\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9583\n",
            "Epoch 199/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9861\n",
            "Epoch 200/200\n",
            "15/15 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save the model\n",
        "model.save('model.h5', hist)"
      ],
      "metadata": {
        "id": "WhXzDc_KCtx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load pickle files\n",
        "words = pickle.load(open('words.pkl', 'rb')) \n",
        "classes = pickle.load(open('classes.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "EqnJjX7eDTUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model = load_model('model.h5')"
      ],
      "metadata": {
        "id": "7sFJauEdDZ23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to clean the sentences\n",
        "def clean_up_sentence(sentence):\n",
        "  sentence_words = nltk.wordpunct_tokenize(sentence)\n",
        "  sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
        "  return sentence_words"
      ],
      "metadata": {
        "id": "SzdG4r0YDdaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to get the bag of words\n",
        "def bag_of_words(sentence):\n",
        "  sentence_words = clean_up_sentence(sentence)\n",
        "  bag = [0]* len(words)\n",
        "  for w in sentence_words:\n",
        "    for i, word in enumerate(words):\n",
        "      if word == w:\n",
        "        bag[i] = 1\n",
        "  return np.array(bag)"
      ],
      "metadata": {
        "id": "3FwpSxgKDf57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip show tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7z_xNvgxKZS",
        "outputId": "c5baea1b-7f7e-42d2-d2c8-5cb04ae29194"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.12.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.9/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, jax, keras, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine-rl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function predict the class based on the sentence\n",
        "def predict_class(sentence):\n",
        "  bow = bag_of_words(sentence)\n",
        "  res = model.predict(np.array([bow]))[0]\n",
        "  ERROR_THRESHOLD = 0.25\n",
        "  results = [[i,r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "\n",
        "  results.sort(key=lambda x: x[1], reverse=True)\n",
        "  return_list = []\n",
        "  for r in results:\n",
        "    return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})\n",
        "  return return_list"
      ],
      "metadata": {
        "id": "HiZummhrDiZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function getting a response the class based on the sentence\n",
        "def get_reponse(intents_list, intents_json):\n",
        "  print(intents_list)\n",
        "  if(float(intents_list[0]['probability']) > 0.85):\n",
        "    tag = intents_list[0]['intent']\n",
        "    list_of_intents = intents_json['intents']\n",
        "    for i in list_of_intents:\n",
        "      if i['tag'] == tag:\n",
        "        result =random.choice(i['responses'])\n",
        "        break\n",
        "  \n",
        "  else:\n",
        "    result =\"Mwihangane, sinshoboye kumva ibyo mwavuze. Nsubiza ibibazo byerekey imyororokere. Mwasubiramo mukambaza kubuzima bwimwororekere mubundi buryo?\"\n",
        "  return result"
      ],
      "metadata": {
        "id": "xv-xg72qDj7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def interact(sentence):\n",
        "#   ints = predict_class(message)\n",
        "#   res = get_reponse(ints, intents)\n",
        "#   return res\n",
        "#   # print(res)"
      ],
      "metadata": {
        "id": "NMWOTQXLbpNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the classifier\n",
        "while True:\n",
        "  message = input(\"\")\n",
        "  ints = predict_class(sentence)\n",
        "  res = get_reponse(ints, intents)\n",
        "  print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "UvWPmRELDnpS",
        "outputId": "26eb4804-5df7-42d2-b0d2-751dc3fc13d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bite se sha? \n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[{'intent': 'gusuhuza', 'probability': '0.9990595'}]\n",
            "ni iki nabashaho kijyane n'amakuru y'imyororokere?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-088dea4fbfa8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# testing the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p75OXkF0MaVC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}